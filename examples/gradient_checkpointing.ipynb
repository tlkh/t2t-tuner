{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a500be",
   "metadata": {},
   "source": [
    "## Gradient Checkpointing\n",
    "\n",
    "A simple example (sentiment analysis task) using gradient checkpointing.\n",
    "\n",
    "Gradient checkpointing allows you to train using less VRAM, but at the cost of recomputing activations that are not stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "879f2edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import t2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83ca3086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e0ec4565d3962e1d\n",
      "Reusing dataset json (../cache/json/default-e0ec4565d3962e1d/0.0.0/d75ead8d5cfcbe67495df0f89bd262f0023257fbbbd94a730313295f3d756d50)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b560a868f6104451a556c029838fb0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_arguments = t2t.TrainerArguments(\n",
    "    # model\n",
    "    model_name_or_path=\"t5-base\",\n",
    "    cache_dir=\"../cache\",\n",
    "    # data inputs\n",
    "    train_file=\"../sample_data/trainlines.json\",\n",
    "    max_source_length=128,\n",
    "    max_target_length=8,\n",
    "    # taining outputs\n",
    "    output_dir=\"/tmp/saved_model\",\n",
    "    overwrite_output_dir=True,\n",
    "    # training settings\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=64,\n",
    "    learning_rate=1e-5,\n",
    "    gradient_checkpointing=True,\n",
    "    prefix=\"predict sentiment: \",\n",
    "    # validation settings\n",
    ")\n",
    "trainer = t2t.Trainer(arguments=trainer_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65fda86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "=======\n",
      "- model name: t5-base\n",
      "- model params:\n",
      "  - train: 222.9 M\n",
      "  - total: 222.9 M\n",
      "  - vocab: 32100\n",
      "- prompt tuning only: False\n"
     ]
    }
   ],
   "source": [
    "trainer.model_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b281e3c3",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "\n",
    "* With checkpointing: 8.4 GB VRAM, 54s runtime\n",
    "* Without checkpointing: 16.1 GB VRAM, 42s runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae58e3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6625ca87d701459d8ed0ad2e717e3c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on train dataset:   0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 8000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /tmp/saved_model/checkpoint-125\n",
      "Configuration saved in /tmp/saved_model/checkpoint-125/config.json\n",
      "Model weights saved in /tmp/saved_model/checkpoint-125/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/saved_model/checkpoint-125/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/saved_model/checkpoint-125/special_tokens_map.json\n",
      "Copy vocab file to /tmp/saved_model/checkpoint-125/spiece.model\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to /tmp/saved_model\n",
      "Configuration saved in /tmp/saved_model/config.json\n",
      "Model weights saved in /tmp/saved_model/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/saved_model/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/saved_model/special_tokens_map.json\n",
      "Copy vocab file to /tmp/saved_model/spiece.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  total_flos               =  1151995GF\n",
      "  train_loss               =     0.9041\n",
      "  train_runtime            = 0:00:53.66\n",
      "  train_samples            =       8000\n",
      "  train_samples_per_second =     149.06\n",
      "  train_steps_per_second   =      2.329\n"
     ]
    }
   ],
   "source": [
    "trainer.train(valid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f40795",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "181e9270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"predict sentiment: This is the worst movie I have ever seen!\"\n",
    "trainer.generate_single(input_text, max_length=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c9980ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"predict sentiment: This is the best movie I have ever seen!\"\n",
    "trainer.generate_single(input_text, max_length=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64baf45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
